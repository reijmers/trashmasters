{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url= 'https://scholar.google.com/scholar'\n",
    "\n",
    "#set headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) \\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36' \n",
    "    #english\n",
    "}\n",
    "\n",
    "\n",
    "params = {\n",
    "    #english\n",
    "    'hl': 'en',\n",
    "\n",
    "    'start': 0,\n",
    "    'q': 'circular economy waste household' \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61110fbe73d947689df1843c7050cc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loop through pages for n pages\n",
    "n = 1\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#store results\n",
    "results = pd.DataFrame(columns=['title', 'link', 'author'])\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    params['start'] = i*10\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('div', class_='gs_ri')\n",
    "\n",
    "    #get titles\n",
    "    titles = [article.find('h3', class_='gs_rt').text for article in articles]\n",
    "    #get links\n",
    "    links = [article.find('h3', class_='gs_rt').find('a')['href'] for article in articles]\n",
    "    #get authors\n",
    "    authors = [article.find('div', class_='gs_a').text for article in articles]\n",
    "    \n",
    "    #add to results\n",
    "    results = results._append(pd.DataFrame({'title': titles, 'link': links, 'author': authors}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_abstract(url):\n",
    "    \"\"\"\n",
    "    Fetch the abstract from the provided arXiv URL using XPath.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): The URL of the arXiv paper.\n",
    "\n",
    "    Returns:\n",
    "    - str: The abstract of the paper.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        abstract = soup.find('blockquote', class_='abstract').text.strip()\n",
    "    \n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "link = 'https://www.sciencedirect.com/science/article/pii/S0921800919302976'\n",
    "\n",
    "response = requests.get(link, headers=headers)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"None\"]\"}\n  (Session info: chrome=119.0.6045.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x009C72A3+45731]\n\t(No symbol) [0x00952D51]\n\t(No symbol) [0x0084880D]\n\t(No symbol) [0x0087B940]\n\t(No symbol) [0x0087BE0B]\n\t(No symbol) [0x008AD1F2]\n\t(No symbol) [0x00898024]\n\t(No symbol) [0x008AB7A2]\n\t(No symbol) [0x00897DD6]\n\t(No symbol) [0x008731F6]\n\t(No symbol) [0x0087439D]\n\tGetHandleVerifier [0x00CD0716+3229462]\n\tGetHandleVerifier [0x00D184C8+3523784]\n\tGetHandleVerifier [0x00D1214C+3498316]\n\tGetHandleVerifier [0x00A51680+611968]\n\t(No symbol) [0x0095CCCC]\n\t(No symbol) [0x00958DF8]\n\t(No symbol) [0x00958F1D]\n\t(No symbol) [0x0094B2C7]\n\tBaseThreadInitThunk [0x75FBFCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77277C6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77277C3E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gur Levy\\trashmasters-6\\scholar scraper\\scholar_scraper.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m driver\u001b[39m.\u001b[39mget(main_page_url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)  \u001b[39m# Wait for the page to load (you can decrease this time if need be)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m doi_input \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_element()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Find search bar -> input URL\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m search_bar \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(by\u001b[39m=\u001b[39mBy\u001b[39m.\u001b[39mID, value\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msearch-bar\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:738\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    735\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    736\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 738\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    345\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"None\"]\"}\n  (Session info: chrome=119.0.6045.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x009C72A3+45731]\n\t(No symbol) [0x00952D51]\n\t(No symbol) [0x0084880D]\n\t(No symbol) [0x0087B940]\n\t(No symbol) [0x0087BE0B]\n\t(No symbol) [0x008AD1F2]\n\t(No symbol) [0x00898024]\n\t(No symbol) [0x008AB7A2]\n\t(No symbol) [0x00897DD6]\n\t(No symbol) [0x008731F6]\n\t(No symbol) [0x0087439D]\n\tGetHandleVerifier [0x00CD0716+3229462]\n\tGetHandleVerifier [0x00D184C8+3523784]\n\tGetHandleVerifier [0x00D1214C+3498316]\n\tGetHandleVerifier [0x00A51680+611968]\n\t(No symbol) [0x0095CCCC]\n\t(No symbol) [0x00958DF8]\n\t(No symbol) [0x00958F1D]\n\t(No symbol) [0x0094B2C7]\n\tBaseThreadInitThunk [0x75FBFCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77277C6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77277C3E+238]\n"
     ]
    }
   ],
>>>>>>> f94f187351a84e6c96356b7c0e296c4a19f16e4e
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "main_page_url = 'https://sci-hub.ru/'\n",
    "url_to_search = 'https://www.sciencedirect.com/science/article/pii/S0921800919302976'\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Open page\n",
    "    driver.get(main_page_url)\n",
    "    time.sleep(2)  # Wait for the page to load (you can decrease this time if need be)\n",
    "\n",
    "    #doi_input = driver.find_element()\n",
    "    # Find search bar -> input URL\n",
    "    search_bar = driver.find_element(by=By.ID, value='request')\n",
    "    search_bar.send_keys(url_to_search)\n",
    "    search_bar.send_keys(Keys.RETURN)  # To submit the search query\n",
    "    time.sleep(1)  # Wait for a bit again\n",
    "\n",
    "    # Find download link\n",
    "    download_button = driver.find_element(by=By.XPATH, value=\"//button[@onclick]\")\n",
    "    onclick_attribute = download_button.get_attribute('onclick')\n",
    "\n",
    "    # Extract URL from the onclick attribute\n",
    "    # Assuming the format is location.href='URL'\n",
    "    pdf_url = onclick_attribute.split(\"'\")[1]\n",
    "    \n",
    "    download_link = 'https://' + urlparse(main_page_url).hostname + pdf_url\n",
    "  \n",
    "    # Download the PDF using requests\n",
    "    response = requests.get(download_link)\n",
    "\n",
    "    with open('pdf.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle the exception, print an error message, etc.\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"doi\"]\"}\n  (Session info: chrome=119.0.6045.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x009C72A3+45731]\n\t(No symbol) [0x00952D51]\n\t(No symbol) [0x0084880D]\n\t(No symbol) [0x0087B940]\n\t(No symbol) [0x0087BE0B]\n\t(No symbol) [0x008AD1F2]\n\t(No symbol) [0x00898024]\n\t(No symbol) [0x008AB7A2]\n\t(No symbol) [0x00897DD6]\n\t(No symbol) [0x008731F6]\n\t(No symbol) [0x0087439D]\n\tGetHandleVerifier [0x00CD0716+3229462]\n\tGetHandleVerifier [0x00D184C8+3523784]\n\tGetHandleVerifier [0x00D1214C+3498316]\n\tGetHandleVerifier [0x00A51680+611968]\n\t(No symbol) [0x0095CCCC]\n\t(No symbol) [0x00958DF8]\n\t(No symbol) [0x00958F1D]\n\t(No symbol) [0x0094B2C7]\n\tBaseThreadInitThunk [0x75FBFCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77277C6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77277C3E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gur Levy\\trashmasters-6\\scholar scraper\\scholar_scraper.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)  \u001b[39m# Wait for the page to load (you can decrease this time if need be)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Find DOI input field and submit the DOI\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m doi_input \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_element(by\u001b[39m=\u001b[39;49mBy\u001b[39m.\u001b[39;49mNAME, value\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdoi\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m doi_input\u001b[39m.\u001b[39msend_keys(doi)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gur%20Levy/trashmasters-6/scholar%20scraper/scholar_scraper.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m doi_input\u001b[39m.\u001b[39msend_keys(Keys\u001b[39m.\u001b[39mRETURN)  \u001b[39m# To submit the DOI\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:738\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    735\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    736\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 738\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    345\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"doi\"]\"}\n  (Session info: chrome=119.0.6045.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x009C72A3+45731]\n\t(No symbol) [0x00952D51]\n\t(No symbol) [0x0084880D]\n\t(No symbol) [0x0087B940]\n\t(No symbol) [0x0087BE0B]\n\t(No symbol) [0x008AD1F2]\n\t(No symbol) [0x00898024]\n\t(No symbol) [0x008AB7A2]\n\t(No symbol) [0x00897DD6]\n\t(No symbol) [0x008731F6]\n\t(No symbol) [0x0087439D]\n\tGetHandleVerifier [0x00CD0716+3229462]\n\tGetHandleVerifier [0x00D184C8+3523784]\n\tGetHandleVerifier [0x00D1214C+3498316]\n\tGetHandleVerifier [0x00A51680+611968]\n\t(No symbol) [0x0095CCCC]\n\t(No symbol) [0x00958DF8]\n\t(No symbol) [0x00958F1D]\n\t(No symbol) [0x0094B2C7]\n\tBaseThreadInitThunk [0x75FBFCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77277C6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77277C3E+238]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import requests\n",
    "\n",
    "main_page_url = 'https://sci-hub.ru/'\n",
    "doi = 'https://doi.org/10.1016/j.ecolecon.2019.106402'\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Open page\n",
    "    driver.get(main_page_url)\n",
    "    time.sleep(2)  # Wait for the page to load (you can decrease this time if need be)\n",
    "\n",
    "    # Find DOI input field and submit the DOI\n",
    "    doi_input = driver.find_element(by=By.ID, value='request')\n",
    "    doi_input.send_keys(doi)\n",
    "    doi_input.send_keys(Keys.RETURN)  # To submit the DOI\n",
    "    time.sleep(1)  # Wait for a bit again\n",
    "\n",
    "    # Find download link\n",
    "    download_button = driver.find_element(by=By.XPATH, value=\"//button[@onclick]\")\n",
    "    onclick_attribute = download_button.get_attribute('onclick')\n",
    "    #download_link_element = driver.find_element(by=By.XPATH, value=\"//ul[@class='mb-4']//li/a[contains(@href, 'scimag')]\")\n",
    "    \n",
    "    download_link_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//ul[@class='mb-4']//li/a[contains(@href, 'scimag')]\"))\n",
    ")\n",
    "    download_link = download_link_element.get_attribute('href')\n",
    "    # Extract URL from the onclick attribute\n",
    "    # Assuming the format is location.href='URL'\n",
    "    #pdf_url = onclick_attribute.split(\"'\")[1]\n",
    "    \n",
    "    #download_link = 'https:' + pdf_url\n",
    "\n",
    "    # Download the PDF using requests\n",
    "    response = requests.get(download_link)\n",
    "    with open('pdf.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "import requests\n",
    "\n",
    "main_page_url = 'https://sci-hub.ru/'\n",
    "url_to_search = 'https://www.sciencedirect.com/science/article/pii/S0959652617320346'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Open page\n",
    "    driver.get(main_page_url)\n",
    "    time.sleep(1)  # Wait for the page to load (you can decrease this time if need be)\n",
    "\n",
    "    # Find search bar -> input URL\n",
    "    search_bar = driver.find_element(by=By.ID, value='request')\n",
    "    search_bar.send_keys(url_to_search)\n",
    "    search_bar.send_keys(Keys.RETURN)  # To submit the search query\n",
    "    time.sleep(1)  # Wait for a bit again\n",
    "\n",
    "    # Find download link\n",
    "    download_button = driver.find_element(by=By.XPATH, value=\"//button[@onclick]\")\n",
    "    onclick_attribute = download_button.get_attribute('onclick')\n",
    "\n",
    "    # Extract URL from the onclick attribute\n",
    "    # Assuming the format is location.href='URL'\n",
    "    pdf_url = onclick_attribute.split(\"'\")[1]\n",
    "    \n",
    "    download_link = 'https:' + pdf_url\n",
    "\n",
    "    # Download the PDF using requests\n",
    "    response = requests.get(download_link)\n",
    "    with open('/pdfs/pdf.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "except:\n",
    "    driver.quit()\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "    main_page_url = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def pdf_download(url_to_search, file_name):\n",
    "    driver = webdriver.Chrome() #initialize web-finder\n",
    "    main_page_url = 'https://sci-hub.ru/' #open sci-hub\n",
    "    driver.get(main_page_url)\n",
    "    time.sleep(1)\n",
    "    # Find search bar -> input URL\n",
    "    search_bar = driver.find_element(by=By.ID, value='request')\n",
    "    search_bar.send_keys(url_to_search)\n",
    "    search_bar.send_keys(Keys.RETURN)  # To submit the search query\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        # Find download link\n",
    "        download_button = driver.find_element(by=By.XPATH, value=\"//button[@onclick]\")\n",
    "        onclick_attribute = download_button.get_attribute('onclick')\n",
    "    except:\n",
    "        driver.quit()\n",
    "        return url_to_search\n",
    "\n",
    "    \n",
    "    # Extract URL from the onclick attribute\n",
    "    # Assuming the format is location.href='URL'\n",
    "    pdf_url = onclick_attribute.split(\"'\")[1]\n",
    "    download_link = 'https://sci-hub.ru' + pdf_url\n",
    "    # Download the PDF using requests\n",
    "    response = requests.get(download_link)\n",
    "    with open(f'pdfs/¨{file_name}.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR FOR https://www.sciencedirect.com/science/article/pii/S0892687522002710\n",
      "ERROR FOR https://www.sciencedirect.com/science/article/pii/S0959652622040185\n",
      "ERROR FOR http://ppeu.stu.cn.ua/article/view/126051\n",
      "ERROR FOR https://www.mdpi.com/2079-9276/9/11/128\n",
      "ERROR FOR https://www.emerald.com/insight/content/doi/10.1108/MEQ-04-2021-0089/full/html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('tmp.csv')\n",
    "title = data['title']\n",
    "links = data['link']\n",
    "author = ['author'] \n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    url_returned = pdf_download(links[index], index)\n",
    "    if url_returned is not None:\n",
    "        print(f'ERROR FOR {url_returned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
