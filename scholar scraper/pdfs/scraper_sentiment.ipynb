{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 PDFs in folder!\n",
      "Analyzing 0.pdf...\n",
      "First paragraph of Discussion section extracted from 0.pdf\n",
      "Analyzing 11.pdf...\n",
      "No Discussion section found in 11.pdf\n",
      "Analyzing 14.pdf...\n",
      "No Discussion section found in 14.pdf\n",
      "Analyzing 15.pdf...\n",
      "First paragraph of Discussion section extracted from 15.pdf\n",
      "Analyzing 16.pdf...\n",
      "First paragraph of Discussion section extracted from 16.pdf\n",
      "Analyzing 17.pdf...\n",
      "First paragraph of Discussion section extracted from 17.pdf\n",
      "Analyzing 19.pdf...\n",
      "No Discussion section found in 19.pdf\n",
      "Analyzing 20.pdf...\n",
      "Error reading 20.pdf: EOF marker not found\n",
      "Analyzing 22.pdf...\n",
      "First paragraph of Discussion section extracted from 22.pdf\n",
      "Analyzing 23.pdf...\n",
      "First paragraph of Discussion section extracted from 23.pdf\n",
      "Analyzing 24.pdf...\n",
      "No Discussion section found in 24.pdf\n",
      "Analyzing 27.pdf...\n",
      "No Discussion section found in 27.pdf\n",
      "Analyzing 29.pdf...\n",
      "Error reading 29.pdf: EOF marker not found\n",
      "Analyzing 3.pdf...\n",
      "First paragraph of Discussion section extracted from 3.pdf\n",
      "Analyzing 30.pdf...\n",
      "First paragraph of Discussion section extracted from 30.pdf\n",
      "Analyzing 35.pdf...\n",
      "No Discussion section found in 35.pdf\n",
      "Analyzing 37.pdf...\n",
      "No Discussion section found in 37.pdf\n",
      "Analyzing 38.pdf...\n",
      "Error reading 38.pdf: EOF marker not found\n",
      "Analyzing 39.pdf...\n",
      "Error reading 39.pdf: EOF marker not found\n",
      "Analyzing 4.pdf...\n",
      "Error reading 4.pdf: EOF marker not found\n",
      "Analyzing 41.pdf...\n",
      "No Discussion section found in 41.pdf\n",
      "Analyzing 42.pdf...\n",
      "Error reading 42.pdf: EOF marker not found\n",
      "Analyzing 46.pdf...\n",
      "Error reading 46.pdf: EOF marker not found\n",
      "Analyzing 47.pdf...\n",
      "Error reading 47.pdf: EOF marker not found\n",
      "Analyzing 48.pdf...\n",
      "Error reading 48.pdf: EOF marker not found\n",
      "Analyzing 58.pdf...\n",
      "Error reading 58.pdf: EOF marker not found\n",
      "Analyzing 59.pdf...\n",
      "Error reading 59.pdf: EOF marker not found\n",
      "Analyzing 61.pdf...\n",
      "Error reading 61.pdf: EOF marker not found\n",
      "Analyzing 8.pdf...\n",
      "First paragraph of Discussion section extracted from 8.pdf\n",
      "Analyzing 9.pdf...\n",
      "Error reading 9.pdf: EOF marker not found\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import re\n",
    "\n",
    "mypath = 'C:\\\\Users\\\\sabri\\\\Desktop\\\\pdfs'\n",
    "\n",
    "pdf_folder_content = [f for f in listdir(mypath) if f.endswith('.pdf')]\n",
    "print(f'Found {len(pdf_folder_content)} PDFs in folder!')\n",
    "\n",
    "for pdf in pdf_folder_content:\n",
    "    print(f'Analyzing {pdf}...')\n",
    "    discussion_text = ''\n",
    "    in_discussion = False\n",
    "\n",
    "    try:\n",
    "        reader = PdfReader(join(mypath, pdf))\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {pdf}: {e}')\n",
    "        continue\n",
    "\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            if 'Discussion' in page_text and not in_discussion:\n",
    "                start_index = page_text.find('Discussion') + len('Discussion')\n",
    "                page_text = page_text[start_index:]  # Consider text after 'Discussion'\n",
    "\n",
    "                # Use regular expression to find the first paragraph\n",
    "                match = re.search(r'([^.]*\\.[^.]*)\\.', page_text)\n",
    "                if match:\n",
    "                    discussion_text = match.group(1).strip()\n",
    "                    break  # Stop after extracting the first paragraph\n",
    "\n",
    "    if discussion_text:\n",
    "        with open(join(mypath, pdf.replace('.pdf', '_discussion_sentences.txt')), 'w') as f:\n",
    "            f.write(discussion_text)\n",
    "        print(f'First paragraph of Discussion section extracted from {pdf}')\n",
    "    else:\n",
    "        print(f'No Discussion section found in {pdf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     ---------------------------------------- 0.0/636.8 kB ? eta -:--:--\n",
      "     --- ----------------------------------- 61.4/636.8 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 430.1/636.8 kB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  634.9/636.8 kB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 636.8/636.8 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\sabri\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\sabri\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\sabri\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sabri\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sabri\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sabri\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for 0_discussion_sentences.txt:\n",
      "Polarity: -0.1, Subjectivity: 0.05\n",
      "\n",
      "Analysis for 15_discussion_sentences.txt:\n",
      "Polarity: 0.0, Subjectivity: 0.0625\n",
      "\n",
      "Analysis for 16_discussion_sentences.txt:\n",
      "Polarity: -0.041666666666666664, Subjectivity: 0.3416666666666667\n",
      "\n",
      "Analysis for 17_discussion_sentences.txt:\n",
      "Polarity: -0.013333333333333332, Subjectivity: 0.23625\n",
      "\n",
      "Analysis for 22_discussion_sentences.txt:\n",
      "Polarity: -0.0375, Subjectivity: 0.475\n",
      "\n",
      "Analysis for 23_discussion_sentences.txt:\n",
      "Polarity: -0.0375, Subjectivity: 0.475\n",
      "\n",
      "Analysis for 30_discussion_sentences.txt:\n",
      "Polarity: -0.1, Subjectivity: 0.39\n",
      "\n",
      "Analysis for 3_discussion_sentences.txt:\n",
      "Polarity: 0.0, Subjectivity: 0.0\n",
      "\n",
      "Analysis for 8_discussion_sentences.txt:\n",
      "Polarity: 0.0, Subjectivity: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "mypath = 'C:\\\\Users\\\\sabri\\\\Desktop\\\\pdfs'\n",
    "\n",
    "discussion_files = [f for f in listdir(mypath) if f.endswith('_discussion_sentences.txt')]\n",
    "\n",
    "for file in discussion_files:\n",
    "    with open(join(mypath, file), 'r') as f:\n",
    "        discussion_text = f.read()\n",
    "\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(discussion_text)\n",
    "\n",
    "    # Get the sentiment\n",
    "    sentiment = blob.sentiment\n",
    "    print(f'Analysis for {file}:')\n",
    "    print(f'Polarity: {sentiment.polarity}, Subjectivity: {sentiment.subjectivity}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
