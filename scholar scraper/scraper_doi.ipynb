{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOOGLE SCHOLAR SEARCH OF KEY WORDS\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url= 'https://scholar.google.com/scholar'\n",
    "\n",
    "#set headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) \\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36' \n",
    "    #english\n",
    "}\n",
    "\n",
    "params = {\n",
    "    #english\n",
    "    'hl': 'en',\n",
    "\n",
    "    'start': 0,\n",
    "    'q': 'circular economy waste household' # maybe add 'trash' 'garbage' 'individual'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1a9b5203fd482fb9fa1c8bf20ae1a8",
       "model_id": "60be3d84f3044dcb828ba0ee428b78aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# extract doi's from url\n",
    "def extract_doi_from_webpage(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            doi_elements = soup.find_all(string=re.compile(r'\\b(10\\.\\d{4,}(?:\\.\\d+)*/\\S+)\\b'))\n",
    "            \n",
    "            if doi_elements:\n",
    "                dois = []\n",
    "                for element in doi_elements:\n",
    "                    match = re.findall(r'\\b(10\\.\\d{4,}(?:\\.\\d+)*/\\S+)\\b', str(element))\n",
    "                    if match:\n",
    "                        #added 'https://doi.org/' in front so that iit can be callable\n",
    "                        dois.extend([f\"https://doi.org/{doi}\" for doi in match])\n",
    "                \n",
    "                return dois \n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None\n",
    "\n",
    "# loop through pages for n pages\n",
    "n = 10\n",
    "\n",
    "results = pd.DataFrame(columns=['titles', 'links', 'authors', 'dois'])\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    params['start'] = i * 10\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('div', class_='gs_ri')\n",
    "\n",
    "    # get titles\n",
    "    titles = [article.find('h3', class_='gs_rt').text for article in articles]\n",
    "    titles = [title[:title.find('[') - 1] if title.find('[') != -1 else title for title in titles]\n",
    "    #get links\n",
    "    links = [article.find('h3', class_='gs_rt').find('a')['href'] for article in articles]\n",
    "    #get authors\n",
    "    authors = [article.find('div', class_='gs_a').text for article in articles]\n",
    "\n",
    "    # get doi, if it is None, keep link ^ as url of article \n",
    "    dois = [extract_doi_from_webpage(link) for link in links]\n",
    "    dois_links = [doi[0] if doi else None for doi in dois]\n",
    "    final_links = [doi if doi else link for doi, link in zip(dois_links, links)]\n",
    "\n",
    "    \n",
    "    results = pd.concat([results, pd.DataFrame({'titles': titles, 'links': final_links, 'authors': authors, 'dois': dois_links})])\n",
    "\n",
    "results.to_csv('article_info3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                titles  \\\n",
      "0   [HTML][HTML] Consumers in a circular economy: ...   \n",
      "1   [HTML][HTML] Circular economy and household e-...   \n",
      "2   [HTML][HTML] Household organic waste: Integrat...   \n",
      "3   [HTML][HTML] Waste prevention, energy recovery...   \n",
      "4   [HTML][HTML] Potential for circular economy in...   \n",
      "..                                                ...   \n",
      "5   Towards a circular economy: A case study of wa...   \n",
      "6   Assessing the Outcomes of Circular Economy and...   \n",
      "7   [PDF][PDF] Effective solid waste management in...   \n",
      "8   [HTML][HTML] Co-production in solid waste mana...   \n",
      "9   [HTML][HTML] Waste treatment company decision-...   \n",
      "\n",
      "                                                links  \\\n",
      "0   https://www.sciencedirect.com/science/article/...   \n",
      "1   https://www.sciencedirect.com/science/article/...   \n",
      "2   https://www.sciencedirect.com/science/article/...   \n",
      "3   https://www.sciencedirect.com/science/article/...   \n",
      "4   https://www.sciencedirect.com/science/article/...   \n",
      "..                                                ...   \n",
      "5             https://doi.org/10.3390/urbansci2040118   \n",
      "6             https://doi.org/10.34306/itsdi.v5i1.609   \n",
      "7   http://www.procedia-esem.eu/pdf/issues/2017/no...   \n",
      "8   https://doi.org/10.1007/s11356-021-14471-8\",\"P...   \n",
      "9   https://www.sciencedirect.com/science/article/...   \n",
      "\n",
      "                                              authors  \\\n",
      "0   D Nainggolan, AB Pedersen, S Smed, KH Zemo… - ...   \n",
      "1   D Sengupta, I Ilankoon, KD Kang, MN Chong - Mi...   \n",
      "2   É Celestino, A Carvalho, JM Palma-Oliveira - J...   \n",
      "3   I de Sadeleer, H Brattebø, P Callewaert - Reso...   \n",
      "4   K Parajuly, H Wenzel - Journal of Cleaner Prod...   \n",
      "..                                                ...   \n",
      "5   Z Allam, DS Jones - Urban Science, 2018 - mdpi...   \n",
      "6   E Dollan, BDK Ramadhan - IAIC Transactions on ...   \n",
      "7   O Oyelola, I Ajiboshin, J Okewole - … Science,...   \n",
      "8   OB Ezeudu, TC Oraelosi, JC Agunwamba… - … Scie...   \n",
      "9   S Snellinx, J Van Meensel, S Farahbakhsh… - Jo...   \n",
      "\n",
      "                                                 dois  \n",
      "0                                                None  \n",
      "1                                                None  \n",
      "2                                                None  \n",
      "3                                                None  \n",
      "4                                                None  \n",
      "..                                                ...  \n",
      "5             https://doi.org/10.3390/urbansci2040118  \n",
      "6             https://doi.org/10.34306/itsdi.v5i1.609  \n",
      "7                                                None  \n",
      "8   https://doi.org/10.1007/s11356-021-14471-8\",\"P...  \n",
      "9                                                None  \n",
      "\n",
      "[100 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(results.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic scraping function\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def pdf_download(url_to_search, file_name):\n",
    "    driver = webdriver.Chrome() #initialize web-finder\n",
    "    main_page_url = 'https://sci-hub.ru/' #open sci-hub\n",
    "    driver.get(main_page_url)\n",
    "    time.sleep(1)\n",
    "    # Find search bar -> input URL\n",
    "    search_bar = driver.find_element(by=By.ID, value='request')\n",
    "    search_bar.send_keys(url_to_search)\n",
    "    search_bar.send_keys(Keys.RETURN)  # To submit the search query\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        # Find download link\n",
    "        download_button = driver.find_element(by=By.XPATH, value=\"//button[@onclick]\")\n",
    "        onclick_attribute = download_button.get_attribute('onclick')\n",
    "    except:\n",
    "        driver.quit()\n",
    "        return url_to_search\n",
    "\n",
    "    \n",
    "    # Extract URL from the onclick attribute\n",
    "    # Assuming the format is location.href='URL'\n",
    "    pdf_url = onclick_attribute.split(\"'\")[1]\n",
    "    download_link = 'https://sci-hub.ru' + pdf_url\n",
    "    # Download the PDF using requests\n",
    "    response = requests.get(download_link)\n",
    "    with open(f'pdfs/{file_name}.pdf', 'wb') as file:\n",
    "       file.write(response.content)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF already downloaded\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"request\"]\"}\n  (Session info: chrome=120.0.6099.71); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7B3AA4D02+56194]\n\t(No symbol) [0x00007FF7B3A104B2]\n\t(No symbol) [0x00007FF7B38B76AA]\n\t(No symbol) [0x00007FF7B39016D0]\n\t(No symbol) [0x00007FF7B39017EC]\n\t(No symbol) [0x00007FF7B3944D77]\n\t(No symbol) [0x00007FF7B3925EBF]\n\t(No symbol) [0x00007FF7B3942786]\n\t(No symbol) [0x00007FF7B3925C23]\n\t(No symbol) [0x00007FF7B38F4A45]\n\t(No symbol) [0x00007FF7B38F5AD4]\n\tGetHandleVerifier [0x00007FF7B3E1D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7B3E76197+4059159]\n\tGetHandleVerifier [0x00007FF7B3E6DF63+4025827]\n\tGetHandleVerifier [0x00007FF7B3B3F029+687785]\n\t(No symbol) [0x00007FF7B3A1B508]\n\t(No symbol) [0x00007FF7B3A17564]\n\t(No symbol) [0x00007FF7B3A176E9]\n\t(No symbol) [0x00007FF7B3A08094]\n\tBaseThreadInitThunk [0x00007FFB48C6257D+29]\n\tRtlUserThreadStart [0x00007FFB4986AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError already encountered\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     url_returned \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{index}\u001b[39;49;00m\u001b[38;5;124;43m.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url_returned \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m         list_error_links\u001b[38;5;241m.\u001b[39mappend(url_returned)\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mpdf_download\u001b[1;34m(url_to_search, file_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Find search bar -> input URL\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m search_bar \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msend_keys(url_to_search)\n\u001b[0;32m     19\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mRETURN)  \u001b[38;5;66;03m# To submit the search query\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\celia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:738\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    735\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    736\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\celia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\celia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"request\"]\"}\n  (Session info: chrome=120.0.6099.71); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7B3AA4D02+56194]\n\t(No symbol) [0x00007FF7B3A104B2]\n\t(No symbol) [0x00007FF7B38B76AA]\n\t(No symbol) [0x00007FF7B39016D0]\n\t(No symbol) [0x00007FF7B39017EC]\n\t(No symbol) [0x00007FF7B3944D77]\n\t(No symbol) [0x00007FF7B3925EBF]\n\t(No symbol) [0x00007FF7B3942786]\n\t(No symbol) [0x00007FF7B3925C23]\n\t(No symbol) [0x00007FF7B38F4A45]\n\t(No symbol) [0x00007FF7B38F5AD4]\n\tGetHandleVerifier [0x00007FF7B3E1D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7B3E76197+4059159]\n\tGetHandleVerifier [0x00007FF7B3E6DF63+4025827]\n\tGetHandleVerifier [0x00007FF7B3B3F029+687785]\n\t(No symbol) [0x00007FF7B3A1B508]\n\t(No symbol) [0x00007FF7B3A17564]\n\t(No symbol) [0x00007FF7B3A176E9]\n\t(No symbol) [0x00007FF7B3A08094]\n\tBaseThreadInitThunk [0x00007FFB48C6257D+29]\n\tRtlUserThreadStart [0x00007FFB4986AA58+40]\n"
     ]
    }
   ],
   "source": [
    "#LOOP THROUGH URLS to downalod by calling the pdf_download function\n",
    "import os\n",
    "data = pd.read_csv('article_info3.csv')\n",
    "list_error_links = []  # Define an empty list to store error links if encountered\n",
    "\n",
    "# Function to check if a file exists at a given path\n",
    "def file_exists(file_path):\n",
    "    return os.path.exists(file_path)\n",
    "\n",
    "# Loop through each row in the DataFrame 'data'\n",
    "for index, row in data.iterrows():\n",
    "    pdf_file_path = f'pdfs/{index}.pdf'  # Define the path for the PDF file\n",
    "    if file_exists(pdf_file_path):\n",
    "        print(\"PDF already downloaded\")\n",
    "    else:\n",
    "        if row['links'] in list_error_links:\n",
    "            print('Error already encountered')\n",
    "        else:\n",
    "            url_returned = pdf_download(row['links'], '{index}.pdf')  \n",
    "            if url_returned is not None:\n",
    "                list_error_links.append(url_returned)\n",
    "                print(f'Error encountered for {url_returned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
